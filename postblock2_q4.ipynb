{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPye8jAgsISiLsJTAILLnsB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/18708064/big-data/blob/master/postblock2_q4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3.1"
      ],
      "metadata": {
        "id": "C00HqWCpGTvp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZtSbXYd4sI01"
      },
      "outputs": [],
      "source": [
        "# Map function\n",
        "def map(filename, content):\n",
        "    # For each character in the content of the file\n",
        "    for char in content:\n",
        "        # Emit the character as the key and the value as 1\n",
        "        EmitIntermediate(char, 1)\n",
        "\n",
        "# Reduce function\n",
        "def reduce(char, values):\n",
        "    # Sum the counts for each character key\n",
        "    result = sum(values)\n",
        "    Emit(char, result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3.5"
      ],
      "metadata": {
        "id": "-o6RAPvjFkyJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combiner function\n",
        "def combiner(char, values):\n",
        "    # Partially sum values before sending to reducer\n",
        "    partial_sum = sum(values)\n",
        "    Emit(char, partial_sum)\n"
      ],
      "metadata": {
        "id": "Eq-IyzYUFhxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4"
      ],
      "metadata": {
        "id": "g_y3oegKFrbJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mapper(hostname, document):\n",
        "    terms = document.split()\n",
        "    term_counts = Counter(terms)\n",
        "    for term, count in term_counts.items():\n",
        "        if count > 1:\n",
        "            yield (hostname, (term, count))\n",
        "\n",
        "\n",
        "def reducer(hostname, term_vectors):\n",
        "    term_frequency = Counter()\n",
        "\n",
        "    # Sum up term frequencies\n",
        "    for term, count in term_vectors:\n",
        "        term_frequency[term] += count\n",
        "\n",
        "    # Emit terms that occur at least twice\n",
        "    filtered_term_vector = {term: count for term, count in term_frequency.items() if count >= 2}\n",
        "\n",
        "    yield (hostname, filtered_term_vector)\n"
      ],
      "metadata": {
        "id": "eH7uK0rqFuQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4.2\n"
      ],
      "metadata": {
        "id": "LgMGH-qnSq_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mapper(hostname, document):\n",
        "    terms = document.split()  # Split the document into words (tokens)\n",
        "    term_counts = Counter(terms)  # Count the occurrences of each term\n",
        "    for term, count in term_counts.items():\n",
        "        if count > 1:  # Only emit terms that appear more than once\n",
        "            yield (hostname, (term, count))\n",
        "\n"
      ],
      "metadata": {
        "id": "0LBTgNTCSta9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reducer(hostname, term_vectors):\n",
        "    term_frequency = Counter()  # Initialize counter to store term frequencies\n",
        "\n",
        "    # Aggregate the term frequencies\n",
        "    for term, count in term_vectors:\n",
        "        term_frequency[term] += count\n",
        "\n",
        "    # Filter and emit terms that occur at least twice\n",
        "    filtered_term_vector = {term: count for term, count in term_frequency.items() if count >= 2}\n",
        "\n",
        "    yield (hostname, filtered_term_vector)\n",
        "\n"
      ],
      "metadata": {
        "id": "RLq3pc72SwGN"
      },
      "execution_count": 4,
      "outputs": []
    }
  ]
}